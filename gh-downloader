#!/bin/zsh

TMP=`mktemp`

for url in $@
do
    echo "Extracting from $url..."
    test -e $TMP.index || curl -s $url > $TMP.index

    # get title
    TITLE=`grep -Po '(?<=<h1 id="gn">)[^<]+' $TMP.index | perl -MHTML::Entities -pne '$_=decode_entities($_); s/\|/./g' `

    echo $TITLE
    test -e $TITLE.cbz && exit

    # pagination
    echo $url > $TMP.pages
    grep -Po '(?<=href=")[^"]*?p=\d+' $TMP.index | sort -u >> $TMP.pages

    i=1
    
    cat $TMP.pages | while read page
    do
	test -e $TMP.page.$i || curl -s $page > $TMP.page.$i

	# parse page for images
	test -e $TMP.images.$i ||
	    grep -Po '(?<=href=")[^"]*?\d-\d+' $TMP.page.$i >> $TMP.images.$i

	cat $TMP.images.$i | while read link
	do
	    curl -s $link | grep -Po '(?<=<img id="img" src=")[^"]+' | wget -q -nc -i -
	    echo -n .
	done
	
	((i=i + 1))
    done

    echo ''
    
    # zip 'em
    \zip -dd -m $TITLE.zip *.jpg
    \zip -dd -m $TITLE.zip *.png
    mv $TITLE.zip $TITLE.cbz
    
    #grep -Po '(?<=href=")[^"]*?\d-\d+' $TMP.index > $TMP.pages
done

rm -f $TMP $TMP.*
